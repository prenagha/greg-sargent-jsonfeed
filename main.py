from bs4 import BeautifulSoup
from datetime import datetime
from zoneinfo import ZoneInfo

import json
import os
import requests

ICON = "https://i.scdn.co/image/ab6765630000ba8ae8bf54498e37d8fc66e985b5"
WEBPAGE = "https://newrepublic.com/podcasts/the-daily-blast-greg-sargent"
HEADERS = {
    'User-Agent':
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.3 '
        'Safari/605.1.15'
}


def log(message):
    now = datetime.now(ZoneInfo('America/New_York'))
    print(now.strftime('%Y-%m-%d %H:%M:%S') + " " + message)


# noinspection PyUnusedLocal
def lambda_handler(event, context):
    return {
        'statusCode': 200,
        'headers': {'Content-Type': 'application/json'},
        'body': get_json_feed(False)
    }


def sorter(el):
    return el["date_published"]


def get_json_feed(debug):
    url = os.environ.get("URL")
    log("HTTP Start " + url)
    html = requests.get(url, headers=HEADERS)
    log("HTTP End")

    if debug:
        post_file = open("data.xml", "w")
        post_file.write(html.text)
        post_file.close()

    log("Parse Start")
    page = BeautifulSoup(html.text, 'html.parser')
    log("Parse End")

    feed_items = []
    for article in page.find_all('item'):
        article_title = article.find('title').text
        if 'Daily Blast' not in article_title:
            continue

        article_title = (article_title.removeprefix('The Daily Blast')
                         .removeprefix(': ').removeprefix('  - ').removeprefix(' - ').strip())
        log(article_title)

        article_id = article.find('guid').text
        article_body = article.find('content:encoded').text

        enclosure = article.find('enclosure')
        mp3_url = enclosure.get('url')
        mp3_type = enclosure.get('type')
        mp3_length = int(enclosure.get('length'))
        mp3_duration = int(article.find('itunes:duration').text)

        article_date_string = article.find('pubdate').text
        #       <pubDate>Tue, 28 Jan 2025 15:39:10 -0000</pubDate>
        article_date = datetime.strptime(article_date_string, "%a, %d %b %Y %H:%M:%S %z").isoformat()

        feed_article = {
            'id': article_id,
            'title': article_title,
            'authors': [{'name': 'Greg Sargent'}],
            'content_html': article_body,
            'date_published': article_date,
            'image': ICON,
            'banner_image': ICON,
            'attachments': [{
                'url': mp3_url,
                'mime_type': mp3_type,
                'size_in_bytes': mp3_length,
                'duration_in_seconds': mp3_duration
            }]
        }
        feed_items.append(feed_article)

    feed = {
        'version': 'https://jsonfeed.org/version/1.1',
        'title': 'Daily Blast+',
        'home_page_url': WEBPAGE,
        'user_comment': 'Generated by https://github.com/prenagha/greg-sargent-jsonfeed',
        'icon': ICON,
        'favicon': ICON,
        'items': sorted(feed_items, key=sorter, reverse=True)
    }
    log("END")
    return json.dumps(feed, indent=2)


def test_feed():
    log('TEST START')
    debug = 'LAMBDA_NAME' not in os.environ
    feed_str = get_json_feed(debug)
    if debug:
        feed_file = open("feed.json", "w")
        feed_file.write(feed_str)
        feed_file.close()
    assert ('date_published' in feed_str)
    log('TEST END')


if __name__ == '__main__':
    test_feed()
